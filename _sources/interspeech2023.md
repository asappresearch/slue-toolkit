
<p style="font: 16px Monaco; margin-left:0em; color:#eb6e6e;">
<b>Interspeech 2023 Special Session</b></p>

# "The 2nd Special Session on Low-Resource Spoken Language Understanding"

Progress in speech processing has been facilitated by shared datasets and benchmarks. Historically these have focused on automatic speech recognition (ASR), speaker identification, or other lower level tasks. Interest has been growing in higher-level spoken language understanding (SLU) tasks, including using end-to-end models, but there are fewer annotated datasets for such tasks, and the existing datasets tend to be relatively small or synthetic. At the same time, recent work shows the possibility of pre-training generic representations and then fine-tuning for several tasks using relatively little labeled data.

For this special session, we will provide a Spoken Language Understanding Evaluation (SLUE) benchmark suite. SLUE phase 1 includes annotation for ASR, named entity recognition (NER) and sentiment analysis with the toolkit to pre-process and fine-tune scripts for baseline models.

While we invite general submissions about this topic, the 2nd special session of the low-resource SLU series incorporates the challenge - [<b>SLUE 2022</b>](./interspeech2023_task_track.md). SLUE 2022 will focus on Named entity recognition using SLUE-Voxpopuli dataset with resource constraints as follows in [<b>here</b>](./interspeech2023_task_track.md).

We also invite contributions for any relevant work in low-resource SLU problems, which include (but are not limited to):

- Training/fine-tuning approach using self/semi-supervised model for SLU tasks
- Comparison between pipeline and end-to-end SLU systems
- Self/semi-supervised learning approach focusing on SLU
- Multi-task/transfer/student-teacher learning focusing on SLU tasks
- Theoretical or empirical study on low-resource SLU problems


<p style="font: 16px Monaco; margin-left:0em; color:#eb6e6e;">
<b> SLUE 2022 Challenge Resources
</b></p>
<p>

Please check [here](./interspeech2023_task_track.md)

</p>




<p style="font: 16px Monaco; margin-left:0em; color:#eb6e6e;">
<b>General Resources
</b></p>

For this special session, we will provide support for several benchmark tasks using the new Spoken Language Understanding Evaluation (SLUE) benchmark suite (https://arxiv.org/abs/2111.10367). SLUE includes annotation for ASR, NER and sentiment analysis. We also provide a toolkit to pre-process and fine-tune scripts for baseline models. It is not mandatory for submissions to use SLUE, but we offer it as a well-defined experiment setting for low-resource SLU.

- SLUE Dataset: \
    - [slue-voxceleb](https://papers-slue.awsdev.asapp.com/slue-voxceleb_blind.tar.gz)
    - [slue-voxpopuli](https://papers-slue.awsdev.asapp.com/slue-voxpopuli_blind.tar.gz)
- SLUE Toolkit: [Github repo](https://github.com/asappresearch/slue-toolkit)
- SLUE Website: [https://asappresearch.github.io/slue-toolkit](https://asappresearch.github.io/slue-toolkit)

Note that there is **no limitation** on use of datasets/benchmarks for the special session. The other datasets/benchmarks we recommend are (alphabetical order)

- [ASR-GLUE](https://arxiv.org/abs/2108.13048)
- [ESPnet-SLU](https://arxiv.org/pdf/2111.14706.pdf)
- [SLURP](https://arxiv.org/abs/2011.13205)
- [SUPERB](http://superbbenchmark.org) (limited to SLU-related tasks)
- [Timers and Such](https://arxiv.org/abs/2104.01604)

<p style="font: 16px Monaco; margin-left:0em; color:#eb6e6e;">
<b>Paper submission
</b></p>

Papers for Interspeech Special Session have to be submitted following the same schedule and procedure as regular papers of INTERSPEECH 2022. The submitted papers will undergo the same review process by anonymous and independent reviewers.

Submission URL : (TBA)

<p style="font: 16px Monaco; margin-left:0em; color:#eb6e6e;">
<b>Important dates
</b></p>

<p style="font: 14px Monaco; margin-left:0em; color:black;line-height:1.4">
(SLUE-Voxpopuli v0.2 dataset has been released through SLUE-Toolkit since 2022) <br><br>
Participants registration start &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : Jan. 01, 2023<br>
Result submission deadline &emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: Feb. 20, 2023<br>
Result announcement (rankings) &emsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : Feb. 22, 2023<br>
Test set label release to participants &emsp;&nbsp;&nbsp;&nbsp;&nbsp;: Feb. 22, 2023<br>
Interspeech 2023 paper submission deadline &emsp;: Mar. 01, 2023<br>
Interspeech 2023 paper update deadline &emsp;&emsp;&emsp;&emsp;&emsp;: Mar. 08, 2023<br>
Interspeech 2023 @ Dublin, Ireland &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;: Aug. 20-24, 2023
</p>

<br><br><br><br><br><br>
